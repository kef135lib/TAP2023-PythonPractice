{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e89c5b3",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [J.D. Porter](https://) for the 2023 Text Analysis Pedagogy Institute, with support from [Constellate](https://constellate.org).\n",
    "\n",
    "For questions/comments/improvements, email porterjd@upenn.sas.edu<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f932d1",
   "metadata": {},
   "source": [
    "# `Finding Word Meaning Through Context` `1`\n",
    "\n",
    "This is lesson `1` of 3 in the educational series on `finding word meaning in context`. This notebook is intended `to teach the basic steps involved in working with text files in Python, and introduce the concepts of programatically reading a text file, analyzing the words it contains, and writing out some results`. \n",
    "\n",
    "**Audience:** `Teachers` / `Learners` / `Researchers`\n",
    "\n",
    "**Use case:** `Tutorial` \n",
    "\n",
    "**Difficulty:** `Beginner`\n",
    "\n",
    "**Completion time:** `90 minutes`\n",
    "\n",
    "**Knowledge Required:** \n",
    "```\n",
    "* Python basics (variables, functions, lists, dictionaries)\n",
    "\n",
    "```\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "```\n",
    "* n/a\n",
    "```\n",
    "\n",
    "**Learning Objectives:**\n",
    "After this lesson, learners will be able to:\n",
    "```\n",
    "1. Open a text file and convert it to a list of words\n",
    "2. \"Clean\" the words using a function\n",
    "3. Find counts and frequencies for the words\n",
    "4. Write out the results of their analysis\n",
    "```\n",
    "**Research Pipeline:**\n",
    "```\n",
    "1. Gather a file in the .txt format and save it somewhere on your machine\n",
    "2. Use whatever steps you're interested in from this notebook\n",
    "3. If you have written out some of your data, explore it in a program like Excel or Google Sheets\n",
    "4. Interpret!\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c0555",
   "metadata": {},
   "source": [
    "# Required Python Libraries\n",
    "\n",
    "* To keep things simple, we will try to work with very few libraries in this notebook (just 'os', which you do not need to install, though you do need to import it)\n",
    "\n",
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10e903-2d6b-4811-aa51-2bf22097055d",
   "metadata": {},
   "source": [
    "# This is a change that i am making to push to github\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5480e2a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dedd148",
   "metadata": {},
   "source": [
    "# Required Data\n",
    "\n",
    "**Data Format:** \n",
    "* plain text (.txt)\n",
    "\n",
    "**Data Source:**\n",
    "* included files (though you may supplement these whenever you feel comfortable doing so!)\n",
    "\n",
    "**Data Quality/Bias:**\n",
    "\n",
    "Included texts are from freely available sources like Project Gutenberg. They have not been vetted for textual accuracy relative to, say, a scholarly edition.\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "This lesson uses textual data in .txt format (utf-8 encoding) from various sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53edaa2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Introduction..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba17a24-94b2-4b8f-bf66-f4d7f8c4fc72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ...to the course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffabbb4-123f-49ff-b8c4-ff23acf1533f",
   "metadata": {},
   "source": [
    "The basic idea behind this course is that we can tell a lot about the meaning of a given word by looking at the words that are used \"near\" it. In our case, this will mean looking at digital copies of texts, treating them as sequences of words, and observing which words tend to appear within a few positions of each other in those sequences.\n",
    "\n",
    "The notion that meaning relies heavily upon context has a long, rich history in linguistics, philosophy of language, natural language processing, and other fields. One important early thinker in this domain (and we'll cast a pretty broad net in describing the domain here) is Ferdinand de Saussure, who argues that words should not be understood as a bunch of names for objects. Rather, they are signs (and often pretty arbitrary signs), and their meaning is determined not by pointing at objects, but by the internal relationships of the broader system in which they exist.[$^{1}$](#1) \n",
    "\n",
    "We find a similar argument at the beginning of Ludwig Wittgenstein's _Philosophical Investigations_, published about a half century after Saussure's work. Wittgenstein begins with a quote from Augustine of Hippo, suggesting that language is learned by pointing at objects and saying their names (an \"ostensive\" model). Wittgenstein point out that a lot of language doesn't seem to function that way (think of someone yelling \"Help!\"), and argues that the Augustinian model is flawed. His ideas (in this period at least) are often summarized with his claim that \"the meaning of a word is its use in the language\".[$^{2}$](#2)  This \"use\" can be quite complex, and involves components that go beyond the presence of other words—for instance, when you yell \"Help!\", the meaning will depend on factors like whether you are flailing in a swimming pool vs. about to drop a stack of plates, your relationships to the people around you, and so on. Still, in a broad sense it does seem like \"use\" must incorporate at least some information about how a word tends to be deployed relative to other words—or in any case, many people have understood Wittgenstein that way.\n",
    "\n",
    "I mention Saussure and Wittgenstein because of their importance in thinking about language as a non-ostensive system in which meaning seems to have something to do with the entire system of the language. But the most relevant context for our work in this course is probably the distributional hypothesis, which has its home more in linguistics. As you might remember from the course description, the linguist J.R. Firth famously said, \"You shall know a word by the company it keeps\". This basic idea arguably sits at the foundation of quite a lot of modern work in linguistics and natural language processing.[$^{3}$](#3) For instance, word vector models generally depend on counting how frequently words appear near each other in a large corpus of text.\n",
    "\n",
    "This leads us to the work of this course, because most distributional models (or contextual theories of language meaning in general) at some point involve _collocates_. \"Collocate\" is a term of art for any word that appears near some target word (if you think of the name as co-locate, you've basically got its meaning). For example, if we looked at a large collection of 1960's and 70's movie reviews, we would probably find that the collocates of \"Connery\" would include words like \"Sean\", \"Bond\", \"007\", and so on—depending on how we measured them, they might even includes things like \"spy\" or \"martini\". \n",
    "\n",
    "With enough of these collocates, would we begin to understand what \"Connery\" _means_ in the context of Cold War cinema? Maybe! By learning to find collocates, we will set ourselves up to think more deeply about questions like these, which remain lively areas of investigation in several disciplines. And we will also make it easier to examine what's going on with specific words or texts (e.g., if you wanted to know how the Supreme Court has discussed \"privacy\" over time, you could use collocates in your investigation). \n",
    "\n",
    "<hr></hr>\n",
    "\n",
    "##### *Footnotes* #####\n",
    "\n",
    "1. <a id=\"1\"></a> The classic Saussure text is his _Course in General Linguistics_.\n",
    "2. <a id=\"2\"></a> _Philsophical Investiations_, 43. For the idea that Wittgenstein's idea of use is _not_ well captured by a distributional semantic model, see Bender, Emily. \"Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data\". _Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics_. 10.18653/v1/2020.acl-main.463\n",
    "3. <a id=\"3\"></a> For a nice overview of distributional semantics in general, see Lenci, Alessandro. \"Distributional Semantics in Linguistic and Cognitive Research\". _Rivista di Linguistica_ 20.1 (2008), pp. 1-31."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225ad44-0d41-4971-bb7d-164e5d4075c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ...to this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1851bbf-1e24-419a-981d-f77e93543358",
   "metadata": {},
   "source": [
    "To get to collocates, we'll need to know how to get to words in the first place. That's the focus of this notebook.\n",
    "\n",
    "There are many ways to go about the tasks described below. Some are arguably more efficient than what we'll learn today; others are matters of preference. The aim here is to give you very basic, flexible, lightweight tools, usable with a pretty minimal level of familiarity with Python.\n",
    "\n",
    "The section headers will give you a good sense of the steps involved, so let's dive in!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb84723-deb5-488f-8504-71721c8d78ab",
   "metadata": {},
   "source": [
    "# Opening a file\n",
    "\n",
    "And reading the text in it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03930633-a32f-4b31-8fe2-c0ea6650d55e",
   "metadata": {},
   "source": [
    "The first thing we need is a path to the file. If the file is in the same directory as your notebook, you can just use the name of the file:\n",
    "\n",
    "```Python\n",
    "fn = 'Austen_PrideAndPrejudice.txt'\n",
    "```\n",
    "\n",
    "If it's anywhere else, you need to give a _path_ to the file, which usually looks something like this:\n",
    "\n",
    "```Python\n",
    "fn = '/Users/porterjd/Documents/TAP/Austen_PrideAndPrejudice.txt'\n",
    "```\n",
    "\n",
    "On a Mac, you can right click a file in Finder, hold \"option\", and select \"Copy 'Austen_PrideAndPrejudice.txt' as Pathname\".\n",
    "\n",
    "To do the equivalent in Windows, hold shift _before_ right clicking on the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966f233-ad26-4ff1-a9c3-034ed740d4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Put your filename here, as the value of the variable \"fn\"\n",
    "\n",
    "fn = 'Austen_PrideAndPrejudice.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7bedf4-4d8f-4978-bfe9-51fba2d18a04",
   "metadata": {},
   "source": [
    "## The verbose way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfe8b6-f6a5-4300-b6d1-f791bfca198a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open the file\n",
    "file = open(fn)\n",
    "\n",
    "# Read the file\n",
    "text = file.read()\n",
    "\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0b395e-77d4-4729-89a5-530d8b3033ef",
   "metadata": {},
   "source": [
    "## The 'Pythonic' way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a739c72-0cff-4edb-80b9-e19f0f2d6ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(fn,encoding='utf8') as source:\n",
    "    text = source.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2054f3-2646-4cc5-8381-a5921ccbdc27",
   "metadata": {},
   "source": [
    "# Turning a text string into words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2eea1-522b-4a54-af5c-1b12e2ab26e8",
   "metadata": {},
   "source": [
    "The **.split()** method turns a string into a list. Basically, the method breaks up the string into sections, each section being demarcated by a specified character. The character itself is removed. By default, it splits on white space (including tabs and new lines), but you can use other characters, too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2bf183-b5c8-48e9-b077-2d244bbdea24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f88cfd6-1a4f-4fec-bc21-dba042ee0e86",
   "metadata": {},
   "source": [
    "# Counting the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a121ce-1c0a-4a00-ab9f-56e5eed9d7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, set up a dictionary. It will take words as keys and store counts as values (though for now it's empty)\n",
    "counts = {}\n",
    "\n",
    "# Next, use a for loop to iterate through our words, counting them as we go\n",
    "# Remember that you can use n += x to increment some variable n by amount x\n",
    "for w in words:\n",
    "    if w not in counts:\n",
    "        counts[w] = 0\n",
    "    counts[w] += 1\n",
    "\n",
    "# Notice any problems with our results? That's why we need the next section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513387cf-950d-4c3e-bc51-4bc9e03d8ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compare counts of 'she' to counts of 'She', or 'said' and 'said,'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1cb75-850f-4658-974c-922b2b2cfcaa",
   "metadata": {},
   "source": [
    "# Cleaning the words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77766d3c-6e90-4bf0-b599-c43359076f7e",
   "metadata": {},
   "source": [
    "In this section, we're going to build a function that takes in a (potentially messy) word and returns a \"cleaned up\" version of the word. We're going to build the function together in an iterative way, testing it out to see what it can do along the way. This can be a useful way to build functions of all kinds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54658331-ef65-4b79-85b1-89c5c5f1985c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to get a useful example sentence\n",
    "\n",
    "sentence = 'She said, \"We should leave,\" and so - with some reservations - we did.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bce13-f4de-4feb-a15e-0aa7ecd77492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_words = sentence.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eadcb9-aaca-4cac-8b56-a6c97e8b5233",
   "metadata": {},
   "source": [
    "#### Some common case methods\n",
    "* .upper()\n",
    "* .lower()\n",
    "* .title()\n",
    "* .casefold()\n",
    "    * Basically a more aggressive form of .lower()\n",
    "    \n",
    "#### Some common character checks\n",
    " * .isalpha()\n",
    " * .isdigit()\n",
    " * .isalnum()\n",
    " \n",
    "#### Some common string checks\n",
    " * .endswith()\n",
    " * .startswith()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2cae1-3f69-4cf0-83e6-370c9c1c3ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Examples for testing the case methods and character checks above\n",
    "\n",
    "a = 'apple123'\n",
    "\n",
    "phrase = 'Ich weiß nicht.'\n",
    "\n",
    "phrase.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8789a8b6-a29c-412f-b671-57e7fdb64d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Takes a word and returns a cleaned up version of the word\n",
    "def wordcleaner(someword):\n",
    "    cleanword = someword.casefold()\n",
    "    while cleanword and not cleanword[-1].isalnum():\n",
    "        cleanword = cleanword[:-1]\n",
    "    while cleanword and not cleanword[0].isalnum():\n",
    "        cleanword = cleanword[1:]\n",
    "    return cleanword\n",
    "\n",
    "# Takes a word and returns an aggressively cleaned version of the word\n",
    "def alphaclean(someword):\n",
    "    letters = [i for i in someword if i.isalpha()]\n",
    "    cleanword = \"\".join(letters)\n",
    "    cleanword = cleanword.casefold()\n",
    "    return cleanword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d705b-a58c-4428-af93-43d9bf91da86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Showing one way to get just the alphabetic characters out of a string\n",
    "\n",
    "letters = [i for i in sample if i.isalpha()]\n",
    "letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e430112-ad87-4a51-bbb1-894f60d1a8c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting a sample word in order to test our wordcleaner function as we build it\n",
    "\n",
    "sample = sentence_words[4]\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ec8bc-3756-4350-b0c4-72adfef4eb3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seeing our wordcleaner function in action on our sample word\n",
    "\n",
    "print(wordcleaner(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11178e5a-38cf-443e-a01a-53459ec156e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seeing our wordcleaner in action on our original sentence words\n",
    "\n",
    "for w in sentence_words:\n",
    "    print(w,\"\\t\",wordcleaner(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03986754-3068-443c-b2f5-88e8bf16e4bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Seeing our alphaclean function in action on our sample word\n",
    "\n",
    "print(alphaclean(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3e4d0-e0d7-4dd5-a756-952f2c1ca537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting our alphacleaned words\n",
    "\n",
    "alpha_counts = {}\n",
    "\n",
    "for w in words:\n",
    "    w = alphaclean(w)\n",
    "    if w not in alpha_counts:\n",
    "        alpha_counts[w] = 0\n",
    "    alpha_counts[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06833d-6aa0-45c9-b779-573e60163803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Word counting results from our wordcleaner method\n",
    "\n",
    "for w in counts:\n",
    "    if \"elizabeth\" in w:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e76e0-ea9f-487b-94ab-8b1f2755dcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Word counting results from our alphaclean method\n",
    "\n",
    "for w in alpha_counts:\n",
    "    if \"elizabeth\" in w:\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76670a61-420d-42ae-b8a2-103758137611",
   "metadata": {},
   "source": [
    "# Counting the words redux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9a7cdd-6705-40e8-9db9-9f5d8081a378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's get our word counts again!\n",
    "counts = {}\n",
    "\n",
    "# Using a list comprehension to clean my words\n",
    "cleanwords = [wordcleaner(w) for w in words]\n",
    "\n",
    "# This is what the list comprehension would look like as a verbose for loop\n",
    "# for w in words:\n",
    "#     cleanwords.append(wordcleaner(w))\n",
    "\n",
    "for w in cleanwords:\n",
    "    if w not in counts:\n",
    "        counts[w] = 0\n",
    "    counts[w] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54374b88-1ce3-41aa-ab56-9239e8ffb5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An alternative way to make your count dictionary\n",
    "for w in cleanwords:\n",
    "    if w in counts:\n",
    "        counts[w] += 1\n",
    "    else:\n",
    "        counts[w] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67562b7e-928d-4bef-988b-322113232f4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sidebar: The hardtack/cherry/electron problem!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c5e0b-2af7-4aaf-a3d0-925662c8754d",
   "metadata": {},
   "source": [
    "_Moby-Dick_ \n",
    "\n",
    "Chapter 23, \"The Lee Shore\"\n",
    "\n",
    "Some chapters back, one Bulkington was spoken of, a tall, newlanded mariner, encountered in New Bedford at the inn.\n",
    "\n",
    "When on that shivering winter’s night, the Pequod thrust her vindictive bows into the cold malicious waves, who should I see standing at her helm but Bulkington! I looked with sympathetic awe and fearfulness upon the man, who in mid-winter just landed from a four years’ dangerous voyage, could so unrestingly push off again for still another tempestuous term. The land seemed scorching to his feet. Wonderfullest things are ever the unmentionable; deep memories yield no epitaphs; this six-inch chapter is the stoneless grave of Bulkington. Let me only say that it fared with him as with the storm-tossed ship, that miserably drives along the leeward land. The port would fain give succor; the port is pitiful; in the port is safety, comfort, hearthstone, supper, warm blankets, friends, all that’s kind to our mortalities. But in that gale, the port, the land, is that ship’s direst jeopardy; she must fly all hospitality; one touch of land, though it but graze the keel, would make her shudder through and through. With all her might she crowds all sail off shore; in so doing, fights ‘gainst the very winds that fain would blow her homeward; seeks all the lashed sea’s landlessness again; for refuge’s sake forlornly rushing into peril; her only friend her bitterest foe!\n",
    "\n",
    "Know ye now, Bulkington? Glimpses do ye seem to see of that mortally intolerable truth; that all deep, earnest thinking is but the intrepid effort of the soul to keep the open independence of her sea; while the wildest winds of heaven and earth conspire to cast her on the treacherous, slavish shore?\n",
    "\n",
    "But as in landlessness alone resides highest truth, shoreless, indefinite as God- so better is it to perish in that howling infinite, than be ingloriously dashed upon the lee, even if that were safety! For worm-like, then, oh! who would craven crawl to land! Terrors of the terrible! is all this agony so vain? Take heart, take heart, O Bulkington! Bear thee grimly, demigod! Up from the spray of thy ocean-perishing- straight up, leaps thy apotheosis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0a37ab-835e-4e51-b9b8-c115835e4e9f",
   "metadata": {},
   "source": [
    "# Writing out some results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca48a7e-9617-47aa-abcc-613e3f8e545a",
   "metadata": {},
   "source": [
    "If you're new to coding, this is where things start to seem kind of magical. We can make a new file on our machines just by writing some code in this notebook. Here, we'll start out learning how to write out any old file, and then we'll try writing out a spreadsheet containing our information about word frequencies.\n",
    "\n",
    "In future work, we'll learn how to write files to different locations on our machines. For now, though, we're going to write things out to the working directory, or in other words the directory containing this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a81da-517c-402c-a534-8d807ee2a364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, let's create a filename for our initial tests of the method\n",
    "output_fn = 'hello_world.txt'\n",
    "\n",
    "# Then let's make a string to write out to the file\n",
    "output_string = \"Hello world!\"\n",
    "\n",
    "# Now we can create the file using a modified version of our \"Pythonic\" approach to opening files\n",
    "with open(output_fn,'w') as output_file:\n",
    "    output_file.write(output_string)\n",
    "\n",
    "# Go check out the file on your machine!\n",
    "# Then close it, and let's try writing more than one thing. Here's a list of animals:\n",
    "\n",
    "animals = ['ant','bug','cat','dog','elk','fly','gnu','hog']\n",
    "\n",
    "# Now let's try with this list:\n",
    "numbers = [512,1729,1864,11251,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c7645-62c3-474e-b07d-862be4abafbd",
   "metadata": {},
   "source": [
    "There are many ways to write out our data. For example, we could write our dictionary, pretty much in its current form, as a .json file. However, spreadsheets are a very useful form for DH (and other kinds of) work. And one useful skill to have in Python is creating a 'table' from some data you have in another format. To do that, we'll use a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812df6c-ee08-441a-8f8d-90d17a89e845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# First, let's set up our output table with the header row we want\n",
    "output_table = [['token_','count']]\n",
    "\n",
    "# Then, let's iterate through our dictionary using a for loop, filling out the table as we go\n",
    "for word,count in counts.items():\n",
    "    new_row = [word,count]\n",
    "    output_table.append(new_row)\n",
    "\n",
    "# Last, let's write out the table!\n",
    "output_fn = 'pp_counts.csv'\n",
    "\n",
    "with open(output_fn,'w') as output_file:\n",
    "    for row in output_table:\n",
    "        str_version = [str(i) for i in row]\n",
    "        output_str = \",\".join(str_version)\n",
    "        output_file.write(output_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91da73-a89f-47fa-9f71-e9034b0b1a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A list of lists can replicate the structure of a table\n",
    "\n",
    "table = [[1,2],[3,4]]\n",
    "\n",
    "# Here's an example of a list of lists looking kind of like a table!\n",
    "for row in table:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b432b044-4817-4b2d-ba46-5e3499a546cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You can grab the key and value from a dictionary using .items()\n",
    "\n",
    "for word,count in counts.items():\n",
    "    print(word,count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7528f-0200-4a09-918c-852d95b60c80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A list comprehension to turn each item in a list into the string version of that item\n",
    "str_version = [str(i) for i in output_table[5]]\n",
    "\n",
    "# A join that connects everything in a list into one big string (with commas between the original items)\n",
    "\",\".join(str_version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
